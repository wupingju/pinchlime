---
title: 回母校分享 ChatGPT & Deep Research 應用的一些心得隨記
date: 2025-02-27
description: 藉由這次的機會，我有意識到研究所與指導老師對我最大的幫助之一，就是不斷地訓練我「提問、限縮範圍、回答問題」的能力，這樣的能力不會有什麼證書去認證，但對我後來在工作上或者跟 AI 的互動上都肯定有幫助！
path: letters/how-i-use-chatgpt-and-deep-research
extra:
  page_type: letter
---

幾週前 OpenAI 的 Deep Research 推出後，我就興奮地跟我讀碩士時的指導老師分享我的體驗感受，過幾天老師問我是否可以回學校分享一下怎麼用 Deep Research ，於是我昨天早上回到學校跟老師＆他的幾位研究助理們分享。

我碩士讀的是科法所，因此我在準備分享內容時就在思考，如果是當年（我是 2021 年畢業的 ）還在讀碩士寫論文的我有了 o1、o1 Pro 與 Deep Researh 可以用，我會怎麼用？我又會在哪些地方避免用 AI ？

順著這個思路，我分享的內容架構大概是：

- 先簡單介紹大語言模型生成內容的機制（預測下一個字詞）
- 介紹這個機制下的一些缺陷（幻覺、仰賴訓練資料、容易受到 prompt 影響產出結果），並且針對幾種缺陷提出一些範例
- 分享新的推理模型（o1 & o1 Pro）的能力以及運作方式，直接套用在相同的幾個範例上，讓大家感受到模型能力進化帶來的差異
- 分享在好的模型基礎上，提供更完整脈絡資訊時，可以產出更好的內容
- 再用同樣的範例，分享透過 Deep Research 去產出分析時可以達到怎樣的更好效果

最後再分享一些我自己的一些零散心得：
- 「生成式 AI」的任務就是「生成」，目前最強的 AI 也沒辦法真的「理解」，若能記得這件事，就可以大幅提高使用生成式 AI 的效果。
- o1 很強， o1 Pro 非常強，之後的模型會更強，現在至少應該要訂閱 ChatGPT Plus 取得 o1 的使用資格。
- 即使有聯網能力，也不代表就肯定正確，還是會受到使用者輸入資訊與網路上資料正確性的影響
- 模型的能力決定了答案的上限，但用戶輸入的脈絡資訊則決定了答案的下限。即使只用普通的模型，只要輸入夠完整的資訊，一樣可以取得很不錯的答案

（以上是概要，因為我並非這方面的專業人士，不太好意思公開分享我寫的完整內容出來）


---

其他心得隨記：

- 我在整理內容時原本想說要不要研究新的 PPT 工具例如 Gamma 之類的，但一打開覺得好像還要學一下，就算了，最後直接建了一個 Heptabase 的白板，把內容都放上去然後畫個線，結果最後發現這樣體驗也很不錯，而且大家也對 Heptabase 蠻有興趣的，真棒！ 😆 
- 平常在網路上寫「怎麼用 AI 工具」，跟真的要分享給別人「我會怎麼用以及為什麼是這樣用」，還是差蠻多的，後者更謹慎一點，所以也要花更多時間準備、思考與規劃內容。這個過程好像也是不錯的學習和反思機會。
- 藉由這次的機會，我有意識到研究所與指導老師對我最大的幫助之一，就是不斷地訓練我「提問、限縮範圍、回答問題」的能力，這樣的能力不會有什麼證書去認證，但對我後來在工作上或者跟 AI 的互動上都肯定有幫助！
- 每次跟我的指導老師聊，就覺得他真的是聰明優秀到不行，很幸運能有這麼好的老師！（我還記得當時寫論文時每次 meeting 都很有收穫，當時就覺得跟聰明人討論東西的感覺真是太棒了）